# Modal SeedVR2 Architecture Flow

## Complete Job Lifecycle (Submission â†’ Completion/Timeout)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER SUBMITS JOB                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    	     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /upscale                                                          â”‚
â”‚  {                                                                      â”‚
â”‚    "video_url": "https://...",                                          â”‚
â”‚    "resolution": "1080p",                                               â”‚
â”‚    "batch_size": 100                                                    â”‚
â”‚  }                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI App (Always Running)                                           â”‚
â”‚  â€¢ Generate job_id = uuid4()                                            â”‚
â”‚  â€¢ Determine GPU: 720p/1080p â†’ H100, 2K â†’ H200	                  â”‚
â”‚  â€¢ Save job to /outputs/jobs/{job_id}.json                              â”‚
â”‚    {                                                                    â”‚
â”‚      "status": "pending",                                               â”‚
â”‚      "gpu_type": "H100",                                                â”‚
â”‚      "created_at": timestamp                                            â”‚
â”‚    }                                                                    â”‚
â”‚  â€¢ Return immediately: {"job_id": "abc-123", "gpu_type": "H100"}        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  asyncio.create_task(process_video, job_id, request)                    â”‚
â”‚  Background task spawned - user doesn't wait                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Modal Function Call (GPU Container Spins Up)                           â”‚
â”‚  â€¢ upscale_video_h100.remote() â†’ Runs on H100 GPU                       
â”‚  â€¢ upscale_video_h200.remote() â†’ Runs on H200 GPU                       
â”‚                                                                         â”‚
â”‚  Container boots with:                                                  â”‚
â”‚  â€¢ PyTorch, CUDA, ffmpeg                                                â”‚
â”‚  â€¢ /models volume (persistent models)                                   â”‚
â”‚  â€¢ /outputs volume (persistent output storage)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  _upscale_video_impl() - Main Processing Function                       â”‚
â”‚                                                                         â”‚
â”‚  PHASE 1: INITIALIZATION                                                â”‚
â”‚  â”œâ”€ git clone SeedVR2 repo â†’ /tmp/seedvr_XXXXX                         
â”‚  â”œâ”€ Download video from URL or decode base64                            â”‚
â”‚  â”œâ”€ Analyze video: width, height, fps, frame_count                      â”‚
â”‚  â””â”€ Calculate stall timeout based on resolution + batch_size            â”‚
â”‚                                                                         â”‚
â”‚  PHASE 2: START PROCESSING + WATCHDOG                                   â”‚
â”‚  â”œâ”€ subprocess.Popen(inference_cli.py) with stdout streaming            â”‚
â”‚  â”œâ”€ Start watchdog_thread() in background                               â”‚
â”‚  â”‚   â””â”€ Every 10s: check if (now - last_heartbeat) > timeout            â”‚
â”‚  â”‚       â””â”€ YES â†’ kill process group + raise exception                 
â”‚  â”‚       â””â”€ NO â†’ continue monitoring                                   
â”‚  â””â”€ Stream logs line by line:                                           
â”‚      â”œâ”€ Any log line â†’ reset last_heartbeat                             
â”‚      â”œâ”€ "Window 0-99" â†’ update progress_dict + job file                 
â”‚      â”œâ”€ "Time batch: 61s" â†’ update progress                             
â”‚      â””â”€ Print all logs to Modal console                                 
â”‚                                                                         
â”‚  PHASE 3: BATCH PROCESSING (Inside inference_cli.py)                     
â”‚  â”œâ”€ Load models (7B DiT + VAE) â†’ ~20s                                   
â”‚  â”œâ”€ Process Window 0-99 (100 frames) â†’ ~62s @ 1080p                     
â”‚  â”œâ”€ Process Window 88-187 (100 frames) â†’ ~62s                           
â”‚  â”œâ”€ Process Window 176-191 (16 frames) â†’ ~11s                           
â”‚  â””â”€ Stitch frames together with crossfade                                â”‚
â”‚                                                                          â”‚
â”‚  PHASE 4: FINALIZATION                                                   â”‚
â”‚  â”œâ”€ Save output.mp4 to /tmp                                              â”‚
â”‚  â”œâ”€ Copy to /outputs/{hash}_{resolution}_{timestamp}.mp4                 â”‚
â”‚  â”œâ”€ Commit volume to persist file                                        â”‚
â”‚  â””â”€ Return {"filename": "...", "input_size_mb": ..., ...}                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                       â”‚
            â–¼                                                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SUCCESS PATH     â”‚                              â”‚   FAILURE PATHS      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                                       â”‚
           â–¼                                                                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Update job status:                 â”‚      â”‚  A) WATCHDOG TIMEOUT       â”‚
â”‚  {                                  â”‚      â”‚  â€¢ No logs for >timeout    â”‚
â”‚    "status": "completed",           â”‚      â”‚  â€¢ watchdog kills process  â”‚
â”‚    "download_url": "https://...",   â”‚      â”‚  â€¢ GPU freed immediately   â”‚
â”‚    "filename": "abc_1080p_123.mp4", â”‚      â”‚                            â”‚
â”‚    "input_size_mb": 0.55,           â”‚      â”‚  â€¢ Mark as "failed"        â”‚
â”‚    "output_size_mb": 6.49           â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  }                                  â”‚                     â”‚
â”‚  â€¢ Save to job file                 â”‚                     â–¼
â”‚  â€¢ Clear from progress_dict         â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  B) PROCESS ERROR          â”‚
        â”‚                                    â”‚  â€¢ inference_cli.py fails  â”‚
        â”‚                                    â”‚  â€¢ returncode != 0         â”‚
        â”‚                                    â”‚  â€¢ Last 20 log lines saved â”‚
        â”‚                                    â”‚  â€¢ Retry (if <2 retries)   â”‚
        â”‚                                    â”‚  â€¢ OR mark as "failed"     â”‚
        â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                                     â”‚
        â”‚                                                     â–¼
        â”‚                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                      â”‚  C) MODAL TIMEOUT (7200s)  â”‚
        â”‚                                      â”‚  â€¢ 2 hour hard limit       â”‚
        â”‚                                      â”‚  â€¢ Container force-killed  â”‚
        â”‚                                      â”‚  â€¢ GPU freed               â”‚
        â”‚                                      â”‚  â€¢ Mark as "failed"        â”‚
        â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU Container Shutdown                                                 â”‚
â”‚  â€¢ Process exits (success or failure)                                   â”‚
â”‚  â€¢ CUDA context destroyed                                               â”‚
â”‚  â€¢ VRAM freed automatically                                             â”‚
â”‚  â€¢ Temp files cleaned up (/tmp/seedvr_XXXXX deleted)                    â”‚
â”‚  â€¢ Container destroyed                                                  â”‚
â”‚  â€¢ GPU available for next job                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## User Polling Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Script: upscale.sh or Python client                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Poll Loop (every 5 seconds)                                            â”‚
â”‚  GET /status/{job_id}                                                   â”‚
â”‚                                                                         â”‚
â”‚  Response:                                                              â”‚
â”‚  {                                                                      â”‚
â”‚    "job_id": "abc-123",                                                 â”‚
â”‚    "status": "processing",                                              â”‚
â”‚    "progress": "ğŸ§© Window 88-187 (len=100)",  â† Real-time!             
â”‚    "elapsed_seconds": 125.3                                             â”‚
â”‚  }                                                                      â”‚
â”‚                                                                         â”‚
â”‚  Progress comes from:                                                   â”‚
â”‚  1. progress_dict (in-memory, FAST) â† Updated every log                
â”‚  2. Job file (persistent) â† Updated periodically                       
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                       â”‚
                        	â–¼                                 â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ status="pending" â”‚    â”‚ status="processing"  
            â”‚ Keep polling...  â”‚    â”‚ Show progress...     
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    	      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                       â”‚
                        	â–¼                                 â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ status="completed"â”‚    â”‚ status="failed"     â”‚
            â”‚ GET /download/... â”‚    â”‚ Show error message  â”‚
            â”‚ Save to disk      â”‚    â”‚ Exit with error     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architecture Components

### 1. **FastAPI App** (Always Running, No GPU)
- **Purpose**: Job queue manager, status API
- **Location**: Modal ASGI function
- **Storage**: `/outputs/jobs/{job_id}.json`
- **Scaling**: Single instance, lightweight

### 2. **GPU Functions** (On-Demand, Short-Lived)
- **Purpose**: Heavy computation (video upscaling)
- **Types**: 
  - `upscale_video_h100()` - 80GB VRAM
  - `upscale_video_h200()` - 141GB VRAM
  - `upscale_video_b200()` - 192GB VRAM
- **Lifecycle**: Boot â†’ Process â†’ Shutdown
- **Scaling**: Up to 10 concurrent containers per GPU type

### 3. **Persistent Volumes**
- **Model Volume** (`/models`):
  - Stores: DiT models, VAE weights, embeddings
  - Shared across all GPU containers
  - ~20GB total
  
- **Output Volume** (`/outputs`):
  - Stores: Final videos, job metadata
  - Shared across FastAPI + GPU containers
  - Grows with usage

### 4. **In-Memory Dict** (`progress_dict`)
- **Purpose**: Ultra-fast real-time progress updates
- **Shared**: Across all Modal functions
- **Lifetime**: Survives container restarts
- **Cleared**: After job completes/fails

### 5. **Watchdog System**
- **Purpose**: Detect and kill stalled jobs
- **Mechanism**: Background thread monitoring heartbeat
- **Timeout**: Dynamic based on resolution + batch size
  - 1080p: ~3-5 min per batch
  - 2K: ~5-8 min per batch
  - 4K: ~8-12 min per batch
- **Action**: `killpg()` â†’ GPU freed immediately

---

## Retry Logic

```
Attempt 1 (Initial)
    â”œâ”€ Success â†’ Done âœ…
    â””â”€ Watchdog Timeout â†’ Attempt 2

Attempt 2 (Retry 1)
    â”œâ”€ Success â†’ Done âœ…
    â””â”€ Watchdog Timeout â†’ Attempt 3

Attempt 3 (Retry 2 - Final)
    â”œâ”€ Success â†’ Done âœ…
    â””â”€ Any Failure â†’ Mark as Failed âŒ
```

**Retry Conditions:**
- âœ… Retries on: Watchdog timeout, transient errors
- âŒ No retry on: Process errors (bad video, OOM), manual kills

---

## Data Flow

```
Video URL/Base64
       â†“
   Download to /tmp
       â†“
   Analyze dimensions
       â†“
   Clone SeedVR2 repo
       â†“
   Run inference_cli.py â”€â”€â†’ [Watchdog monitors]
       â†“                           â†“
   Extract frames            No logs for >timeout?
       â†“                           â†“
   Load models (from /models)     Kill process
       â†“                           â†“
   Process batches            GPU freed
       â†“
   Stitch frames
       â†“
   Encode to MP4
       â†“
   Save to /outputs â”€â”€â”€â”€â”€â†’ [User downloads]
       â†“
   Update job status
       â†“
   Clean up /tmp
       â†“
   Container shutdown
       â†“
   GPU freed
```

---

## Timeout Hierarchy

```
Level 1: Watchdog (Batch-Level)
â”œâ”€ 1080p batch: ~3-5 min
â”œâ”€ 2K batch: ~5-8 min
â””â”€ 4K batch: ~8-12 min
    â†“
    If stalled: Kill process + Retry

Level 2: Modal Timeout (Job-Level)
â”œâ”€ Hard limit: 7200s (2 hours)
â””â”€ If exceeded: Force kill + No retry

Level 3: Network Timeout
â”œâ”€ Download video: 300s (5 min)
â””â”€ If exceeded: Job fails immediately
```

---

## Resource Management

| Resource        | Lifecycle                  | Cleanup              |
|-----------------|----------------------------|----------------------|
| GPU Container   | Per job                    | Auto (on exit)       |
| VRAM            | During processing          | Auto (on exit)       |
| Temp files      | Per job in /tmp            | Manual (shutil.rmtree) |
| Model cache     | Persistent (/models)       | Never (shared)       |
| Output files    | Persistent (/outputs)      | Manual (user deletes)|
| Progress dict   | Per job (in-memory)        | Manual (del dict[id])|
| Job metadata    | Persistent (JSON files)    | Manual (user deletes)|

---

## Summary

**Key Strengths:**
âœ… Dynamic GPU selection (H100/H200/B200)
âœ… Real-time progress updates
âœ… Automatic stall detection and recovery
âœ… Retry logic for transient failures
âœ… Persistent storage for models and outputs
âœ… Automatic GPU cleanup

**Key Constraints:**
âš ï¸ 2-hour hard timeout per job
âš ï¸ Max 10 concurrent containers per GPU type
âš ï¸ Network access limited to approved domains
âš ï¸ No cross-container communication

**Flow Duration Examples:**
- 8-sec 1080p video: ~4 min total
- 8-sec 2K video: ~8 min total
